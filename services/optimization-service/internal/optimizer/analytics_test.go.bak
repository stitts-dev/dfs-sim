package optimizer

import (
	"testing"
	"time"

	"github.com/google/uuid"
	"github.com/stitts-dev/dfs-sim/shared/types"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
)

func TestAnalyticsEngine_CalculatePlayerAnalytics(t *testing.T) {
	engine := NewAnalyticsEngine()

	t.Run("ValidPlayerBasicAnalytics", func(t *testing.T) {
		player := types.Player{
			ID:              uuid.New(),
			Name:            "Test Player",
			Position:        "PG",
			SalaryDK:        8000,
			SalaryFD:        7500,
			ProjectedPoints: 40.0,
			FloorPoints:     25.0,
			CeilingPoints:   55.0,
			OwnershipDK:     15.0,
			IsInjured:       false,
		}

		historicalData := []PerformanceData{
			{Points: 35.0, Salary: 8000, Ownership: 12.0, GameDate: time.Now().AddDate(0, 0, -1)},
			{Points: 42.0, Salary: 8200, Ownership: 18.0, GameDate: time.Now().AddDate(0, 0, -2)},
			{Points: 38.0, Salary: 7800, Ownership: 14.0, GameDate: time.Now().AddDate(0, 0, -3)},
			{Points: 45.0, Salary: 8500, Ownership: 22.0, GameDate: time.Now().AddDate(0, 0, -4)},
			{Points: 30.0, Salary: 7600, Ownership: 10.0, GameDate: time.Now().AddDate(0, 0, -5)},
		}

		analytics, err := engine.CalculatePlayerAnalytics(player, historicalData)

		require.NoError(t, err)
		require.NotNil(t, analytics)

		// Basic validations
		assert.Equal(t, 40.0, analytics.BaseProjection)
		assert.Greater(t, analytics.Ceiling, analytics.BaseProjection, "Ceiling should be greater than base projection")
		assert.Less(t, analytics.Floor, analytics.BaseProjection, "Floor should be less than base projection")
		assert.Greater(t, analytics.ValueRating, 0.0, "Value rating should be positive")
		assert.GreaterOrEqual(t, analytics.Volatility, 0.0, "Volatility should be non-negative")
		assert.GreaterOrEqual(t, analytics.Consistency, 0.0, "Consistency should be non-negative")
		assert.LessOrEqual(t, analytics.Consistency, 1.0, "Consistency should not exceed 1.0")

		// Advanced validations
		assert.Greater(t, analytics.UpsideRatio, 1.0, "Upside ratio should be greater than 1")
		assert.Greater(t, analytics.DownsideRisk, 0.0, "Downside risk should be positive")
		assert.Greater(t, analytics.TournamentScore, 0.0, "Tournament score should be positive")
		assert.Greater(t, analytics.CashGameScore, 0.0, "Cash game score should be positive")

		// Probability validations
		assert.GreaterOrEqual(t, analytics.CeilingProbability, 0.05, "Ceiling probability should be at least 5%")
		assert.LessOrEqual(t, analytics.CeilingProbability, 0.35, "Ceiling probability should not exceed 35%")
		assert.GreaterOrEqual(t, analytics.FloorProbability, 0.05, "Floor probability should be at least 5%")
		assert.LessOrEqual(t, analytics.FloorProbability, 0.35, "Floor probability should not exceed 35%")
	})

	t.Run("InvalidPlayerData", func(t *testing.T) {
		invalidPlayer := types.Player{
			ID:              uuid.New(),
			Name:            "Invalid Player",
			Position:        "PG",
			SalaryDK:        0, // Invalid salary
			ProjectedPoints: 0, // Invalid projection
		}

		analytics, err := engine.CalculatePlayerAnalytics(invalidPlayer, []PerformanceData{})

		assert.Error(t, err)
		assert.Nil(t, analytics)
	})

	t.Run("NoHistoricalData", func(t *testing.T) {
		player := types.Player{
			ID:              uuid.New(),
			Name:            "New Player",
			Position:        "SG",
			SalaryDK:        6000,
			ProjectedPoints: 25.0,
			FloorPoints:     15.0,
			CeilingPoints:   35.0,
		}

		analytics, err := engine.CalculatePlayerAnalytics(player, []PerformanceData{})

		require.NoError(t, err)
		require.NotNil(t, analytics)

		// Should use default estimations
		assert.Equal(t, 25.0, analytics.BaseProjection)
		assert.Greater(t, analytics.Ceiling, analytics.BaseProjection)
		assert.Less(t, analytics.Floor, analytics.BaseProjection)
		assert.Greater(t, analytics.Volatility, 0.0)
	})

	t.Run("HighProjectionPlayer", func(t *testing.T) {
		superstar := types.Player{
			ID:              uuid.New(),
			Name:            "Superstar Player",
			Position:        "PG",
			SalaryDK:        12000,
			ProjectedPoints: 60.0,
			FloorPoints:     45.0,
			CeilingPoints:   75.0,
		}

		analytics, err := engine.CalculatePlayerAnalytics(superstar, []PerformanceData{})

		require.NoError(t, err)
		require.NotNil(t, analytics)

		// High projection players should be more consistent
		assert.Less(t, analytics.Volatility, 0.30, "High projection players should have lower volatility")
		assert.Greater(t, analytics.Consistency, 0.70, "High projection players should have higher consistency")
		assert.Greater(t, analytics.ValueRating, 4.0, "High projection should have good value")
	})

	t.Run("ValuePlayer", func(t *testing.T) {
		valuePlayer := types.Player{
			ID:              uuid.New(),
			Name:            "Value Player",
			Position:        "C",
			SalaryDK:        4000,
			ProjectedPoints: 20.0,
			FloorPoints:     10.0,
			CeilingPoints:   35.0,
		}

		analytics, err := engine.CalculatePlayerAnalytics(valuePlayer, []PerformanceData{})

		require.NoError(t, err)
		require.NotNil(t, analytics)

		// Value players should have higher volatility but good value rating
		assert.Greater(t, analytics.Volatility, 0.30, "Value players typically have higher volatility")
		assert.Greater(t, analytics.ValueRating, 4.5, "Value players should have excellent value rating")
	})
}

func TestAnalyticsEngine_CalculateBulkAnalytics(t *testing.T) {
	engine := NewAnalyticsEngine()

	t.Run("BulkAnalyticsProcessing", func(t *testing.T) {
		players := []types.Player{
			{
				ID:              uuid.New(),
				Name:            "Player 1",
				Position:        "PG",
				SalaryDK:        8000,
				ProjectedPoints: 40.0,
			},
			{
				ID:              uuid.New(),
				Name:            "Player 2",
				Position:        "SG",
				SalaryDK:        7000,
				ProjectedPoints: 35.0,
			},
			{
				ID:              uuid.New(),
				Name:            "Player 3",
				Position:        "SF",
				SalaryDK:        6000,
				ProjectedPoints: 30.0,
			},
		}

		historicalDataMap := make(map[uint][]PerformanceData)
		for _, player := range players {
			playerID := uint(player.ID.ID())
			historicalDataMap[playerID] = []PerformanceData{
				{Points: player.ProjectedPoints - 5, GameDate: time.Now().AddDate(0, 0, -1)},
				{Points: player.ProjectedPoints + 5, GameDate: time.Now().AddDate(0, 0, -2)},
				{Points: player.ProjectedPoints, GameDate: time.Now().AddDate(0, 0, -3)},
			}
		}

		analyticsMap, err := engine.CalculateBulkAnalytics(players, historicalDataMap)

		require.NoError(t, err)
		require.NotNil(t, analyticsMap)
		assert.Len(t, analyticsMap, 3, "Should have analytics for all 3 players")

		for _, player := range players {
			playerID := uint(player.ID.ID())
			analytics, exists := analyticsMap[playerID]
			require.True(t, exists, "Analytics should exist for player %s", player.Name)
			require.NotNil(t, analytics, "Analytics should not be nil for player %s", player.Name)
			assert.Equal(t, player.ProjectedPoints, analytics.BaseProjection, "Base projection should match for player %s", player.Name)
		}
	})

	t.Run("EmptyPlayerList", func(t *testing.T) {
		analyticsMap, err := engine.CalculateBulkAnalytics([]types.Player{}, make(map[uint][]PerformanceData))

		require.NoError(t, err)
		assert.Empty(t, analyticsMap)
	})

	t.Run("SomeInvalidPlayers", func(t *testing.T) {
		players := []types.Player{
			{
				ID:              uuid.New(),
				Name:            "Valid Player",
				Position:        "PG",
				SalaryDK:        8000,
				ProjectedPoints: 40.0,
			},
			{
				ID:              uuid.New(),
				Name:            "Invalid Player",
				Position:        "SG",
				SalaryDK:        0, // Invalid
				ProjectedPoints: 0, // Invalid
			},
		}

		analyticsMap, err := engine.CalculateBulkAnalytics(players, make(map[uint][]PerformanceData))

		require.NoError(t, err)
		assert.Len(t, analyticsMap, 1, "Should only have analytics for valid player")

		validPlayerID := uint(players[0].ID.ID())
		assert.Contains(t, analyticsMap, validPlayerID)
	})
}

func TestAnalyticsEngine_PerformanceCalculations(t *testing.T) {
	engine := NewAnalyticsEngine()

	t.Run("VolatilityCalculation", func(t *testing.T) {
		// Test volatility with different data patterns
		testCases := []struct {
			name        string
			baseProj    float64
			data        []PerformanceData
			expectRange [2]float64 // min, max expected volatility
		}{
			{
				name:     "ConsistentPerformance",
				baseProj: 30.0,
				data: []PerformanceData{
					{Points: 29.0}, {Points: 30.0}, {Points: 31.0}, {Points: 30.5}, {Points: 29.5},
				},
				expectRange: [2]float64{0.0, 0.15}, // Low volatility
			},
			{
				name:     "HighVolatilityPerformance",
				baseProj: 30.0,
				data: []PerformanceData{
					{Points: 10.0}, {Points: 50.0}, {Points: 15.0}, {Points: 45.0}, {Points: 25.0},
				},
				expectRange: [2]float64{0.4, 1.0}, // High volatility
			},
			{
				name:        "NoHistoricalData",
				baseProj:    45.0,
				data:        []PerformanceData{},
				expectRange: [2]float64{0.2, 0.3}, // Default range for high projection
			},
		}

		for _, tc := range testCases {
			t.Run(tc.name, func(t *testing.T) {
				volatility := engine.calculateVolatility(tc.baseProj, tc.data)
				assert.GreaterOrEqual(t, volatility, tc.expectRange[0], "Volatility should be at least %f", tc.expectRange[0])
				assert.LessOrEqual(t, volatility, tc.expectRange[1], "Volatility should be at most %f", tc.expectRange[1])
			})
		}
	})

	t.Run("FloorCeilingCalculation", func(t *testing.T) {
		baseProjection := 35.0
		historicalData := []PerformanceData{
			{Points: 20.0}, {Points: 25.0}, {Points: 30.0}, {Points: 35.0}, {Points: 40.0},
			{Points: 45.0}, {Points: 50.0}, {Points: 32.0}, {Points: 38.0}, {Points: 28.0},
		}

		floor, ceiling := engine.calculateFloorCeiling(baseProjection, historicalData)

		assert.Greater(t, ceiling, baseProjection, "Ceiling should be greater than base projection")
		assert.Less(t, floor, baseProjection, "Floor should be less than base projection")
		assert.Greater(t, ceiling, floor, "Ceiling should be greater than floor")

		// Should be reasonable percentiles
		assert.GreaterOrEqual(t, floor, 20.0, "Floor should be reasonable given data")
		assert.LessOrEqual(t, ceiling, 50.0, "Ceiling should be reasonable given data")
	})

	t.Run("OwnershipEstimation", func(t *testing.T) {
		testCases := []struct {
			valueRating      float64
			expectedRange    [2]float64
			expectedCategory string
		}{
			{valueRating: 7.0, expectedRange: [2]float64{25.0, 45.0}, expectedCategory: "high_value"},
			{valueRating: 5.5, expectedRange: [2]float64{15.0, 25.0}, expectedCategory: "medium_value"},
			{valueRating: 3.0, expectedRange: [2]float64{5.0, 15.0}, expectedCategory: "low_value"},
		}

		for _, tc := range testCases {
			t.Run(tc.expectedCategory, func(t *testing.T) {
				ownership := engine.estimateOwnership(tc.valueRating)
				assert.GreaterOrEqual(t, ownership, tc.expectedRange[0], "Ownership should be at least %f for %s", tc.expectedRange[0], tc.expectedCategory)
				assert.LessOrEqual(t, ownership, tc.expectedRange[1], "Ownership should be at most %f for %s", tc.expectedRange[1], tc.expectedCategory)
			})
		}
	})
}

func TestAnalyticsEngine_ObjectiveScoring(t *testing.T) {
	engine := NewAnalyticsEngine()

	// Create a test player with analytics
	player := types.Player{
		ID:              uuid.New(),
		Name:            "Test Player",
		Position:        "PG",
		SalaryDK:        8000,
		ProjectedPoints: 40.0,
	}

	analytics := &PlayerAnalytics{
		PlayerID:            uint(player.ID.ID()),
		BaseProjection:      40.0,
		Ceiling:             55.0,
		Floor:               25.0,
		Volatility:          0.3,
		ValueRating:         5.0,
		OwnershipProjection: 15.0,
		CeilingProbability:  0.20,
		FloorProbability:    0.15,
		ConsistencyScore:    0.77,
		UpsideRatio:         1.375,
		DownsideRisk:        15.0,
		SafetyScore:         0.625,
		TournamentScore:     45.0,
		CashGameScore:       38.0,
	}

	enhancedPlayer := EnhancedPlayer{
		Player:    player,
		Analytics: analytics,
	}

	t.Run("CeilingObjective", func(t *testing.T) {
		score := engine.GetObjectiveScore(enhancedPlayer, MaxCeiling)
		assert.Equal(t, analytics.TournamentScore, score, "Ceiling objective should return tournament score")
	})

	t.Run("FloorObjective", func(t *testing.T) {
		score := engine.GetObjectiveScore(enhancedPlayer, MaxFloor)
		assert.Equal(t, analytics.CashGameScore, score, "Floor objective should return cash game score")
	})

	t.Run("BalancedObjective", func(t *testing.T) {
		score := engine.GetObjectiveScore(enhancedPlayer, Balanced)
		expectedScore := (analytics.TournamentScore + analytics.CashGameScore) / 2.0
		assert.Equal(t, expectedScore, score, "Balanced objective should return average of tournament and cash scores")
	})

	t.Run("ContrariansObjective", func(t *testing.T) {
		score := engine.GetObjectiveScore(enhancedPlayer, Contrarian)
		// Should penalize ownership
		assert.Less(t, score, analytics.BaseProjection, "Contrarian objective should penalize for ownership")
	})

	t.Run("ValueObjective", func(t *testing.T) {
		score := engine.GetObjectiveScore(enhancedPlayer, Value)
		assert.Equal(t, analytics.ValueRating, score, "Value objective should return value rating")
	})

	t.Run("NoAnalytics", func(t *testing.T) {
		playerWithoutAnalytics := EnhancedPlayer{
			Player:    player,
			Analytics: nil,
		}
		score := engine.GetObjectiveScore(playerWithoutAnalytics, MaxCeiling)
		assert.Equal(t, player.ProjectedPoints, score, "Should fallback to base projection when no analytics")
	})
}

func TestAnalyticsEngine_EdgeCases(t *testing.T) {
	engine := NewAnalyticsEngine()

	t.Run("ExtremeProjections", func(t *testing.T) {
		extremePlayer := types.Player{
			ID:              uuid.New(),
			Name:            "Extreme Player",
			Position:        "C",
			SalaryDK:        3000,
			ProjectedPoints: 100.0, // Extreme projection
		}

		analytics, err := engine.CalculatePlayerAnalytics(extremePlayer, []PerformanceData{})

		require.NoError(t, err)
		require.NotNil(t, analytics)

		// Should handle extreme values gracefully
		assert.Greater(t, analytics.ValueRating, 30.0, "Should have very high value rating")
		assert.Less(t, analytics.Volatility, 0.30, "High projections should have lower volatility")
	})

	t.Run("MinimumSalaryPlayer", func(t *testing.T) {
		minPlayer := types.Player{
			ID:              uuid.New(),
			Name:            "Minimum Player",
			Position:        "PG",
			SalaryDK:        3000,
			ProjectedPoints: 5.0,
		}

		analytics, err := engine.CalculatePlayerAnalytics(minPlayer, []PerformanceData{})

		require.NoError(t, err)
		require.NotNil(t, analytics)

		// Should handle minimum values
		assert.Greater(t, analytics.ValueRating, 0.0, "Should have positive value rating")
		assert.Greater(t, analytics.Volatility, 0.35, "Low projections should have higher volatility")
	})

	t.Run("InjuredPlayer", func(t *testing.T) {
		injuredPlayer := types.Player{
			ID:              uuid.New(),
			Name:            "Injured Player",
			Position:        "SF",
			SalaryDK:        7000,
			ProjectedPoints: 30.0,
			IsInjured:       true,
			InjuryStatus:    "Q",
		}

		analytics, err := engine.CalculatePlayerAnalytics(injuredPlayer, []PerformanceData{})

		require.NoError(t, err)
		require.NotNil(t, analytics)

		// Should factor in injury risk
		assert.Less(t, analytics.CashGameScore, analytics.TournamentScore, "Injured players should have lower cash game scores")
	})
}

// Benchmark tests for performance validation
func BenchmarkAnalyticsEngine_SinglePlayer(b *testing.B) {
	engine := NewAnalyticsEngine()
	player := types.Player{
		ID:              uuid.New(),
		Name:            "Benchmark Player",
		Position:        "PG",
		SalaryDK:        8000,
		ProjectedPoints: 40.0,
	}

	historicalData := make([]PerformanceData, 20)
	for i := range historicalData {
		historicalData[i] = PerformanceData{
			Points:   35.0 + float64(i%10),
			GameDate: time.Now().AddDate(0, 0, -i),
		}
	}

	b.ResetTimer()
	for i := 0; i < b.N; i++ {
		_, err := engine.CalculatePlayerAnalytics(player, historicalData)
		if err != nil {
			b.Fatalf("Analytics calculation failed: %v", err)
		}
	}
}

func BenchmarkAnalyticsEngine_BulkProcessing(b *testing.B) {
	engine := NewAnalyticsEngine()

	// Create 100 test players
	players := make([]types.Player, 100)
	historicalDataMap := make(map[uint][]PerformanceData)

	for i := range players {
		players[i] = types.Player{
			ID:              uuid.New(),
			Name:            fmt.Sprintf("Player %d", i+1),
			Position:        []string{"PG", "SG", "SF", "PF", "C"}[i%5],
			SalaryDK:        5000 + i*50,
			ProjectedPoints: 20.0 + float64(i)*0.5,
		}

		playerID := uint(players[i].ID.ID())
		historicalDataMap[playerID] = []PerformanceData{
			{Points: players[i].ProjectedPoints - 5, GameDate: time.Now().AddDate(0, 0, -1)},
			{Points: players[i].ProjectedPoints + 5, GameDate: time.Now().AddDate(0, 0, -2)},
			{Points: players[i].ProjectedPoints, GameDate: time.Now().AddDate(0, 0, -3)},
		}
	}

	b.ResetTimer()
	for i := 0; i < b.N; i++ {
		_, err := engine.CalculateBulkAnalytics(players, historicalDataMap)
		if err != nil {
			b.Fatalf("Bulk analytics calculation failed: %v", err)
		}
	}
}

// Helper function to create test players
func createTestPlayer(name, position string, salary int, projection float64) types.Player {
	return types.Player{
		ID:              uuid.New(),
		Name:            name,
		Position:        position,
		SalaryDK:        salary,
		ProjectedPoints: projection,
		FloorPoints:     projection * 0.7,
		CeilingPoints:   projection * 1.4,
		OwnershipDK:     15.0,
	}
}

// Helper function to create historical data
func createHistoricalData(basePoints float64, variance float64, games int) []PerformanceData {
	data := make([]PerformanceData, games)
	for i := 0; i < games; i++ {
		// Simple variance simulation
		adjustment := (float64(i%3) - 1.0) * variance
		data[i] = PerformanceData{
			Points:   basePoints + adjustment,
			GameDate: time.Now().AddDate(0, 0, -i-1),
		}
	}
	return data
}